{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import wget\n",
    "import math\n",
    "import scipy.cluster as cluster\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "object_categories = tv.datasets.Caltech256(root='./data', download=False, \n",
    "                                           transform=tv.transforms.Compose(\n",
    "                                               [tv.transforms.ToTensor(),\n",
    "                                                tv.transforms.Normalize((0.58688, 0.59013, 0.58950),(0.1565, 0.1607, 0.1636))]\n",
    "                                                                            ))\n",
    "\n",
    "\n",
    "# Define the proportions for the train and test sets\n",
    "train_proportion = 0.8  # 80% for training, adjust as needed\n",
    "dataset_size = len(object_categories)\n",
    "train_size = int(train_proportion * dataset_size)\n",
    "test_size = dataset_size - train_size\n",
    "\n",
    "# Use random_split to create train and test datasets\n",
    "train_dataset, test_dataset = random_split(object_categories, [train_size, test_size])\n",
    "\n",
    "# You can create DataLoader instances for each dataset for easier handling during training and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x28d75499190>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Caltech256' object has no attribute 'classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matti\\Documents\\GitHub\\CognitionComputation-Project\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Visualize a random image from the first 5 classes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     visualize_random_image(object_categories, class_labels)\n",
      "\u001b[1;32mc:\\Users\\matti\\Documents\\GitHub\\CognitionComputation-Project\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m class_label \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(class_labels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Find images from the selected class\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m class_indices \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(dataset)) \u001b[39mif\u001b[39;49;00m class_label \u001b[39m==\u001b[39;49m dataset\u001b[39m.\u001b[39;49mclasses[dataset\u001b[39m.\u001b[39;49mtargets[i]]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m class_indices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo images found for class \u001b[39m\u001b[39m{\u001b[39;00mclass_label\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\matti\\Documents\\GitHub\\CognitionComputation-Project\\main.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m class_label \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mchoice(class_labels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Find images from the selected class\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m class_indices \u001b[39m=\u001b[39m [i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(dataset)) \u001b[39mif\u001b[39;00m class_label \u001b[39m==\u001b[39m dataset\u001b[39m.\u001b[39;49mclasses[dataset\u001b[39m.\u001b[39mtargets[i]]]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m class_indices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/matti/Documents/GitHub/CognitionComputation-Project/main.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo images found for class \u001b[39m\u001b[39m{\u001b[39;00mclass_label\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Caltech256' object has no attribute 'classes'"
     ]
    }
   ],
   "source": [
    "class_labels = [\"001.ak47\", \"002.american-flag\", \"003.backpack\", \"004.baseball-bat\", \"005.baseball-glove\"]\n",
    "\n",
    "# Create a function to display a random image from the specified class\n",
    "def visualize_random_image(dataset, class_labels):\n",
    "    class_label = random.choice(class_labels)\n",
    "    \n",
    "    # Find images from the selected class\n",
    "    class_indices = [i for i in range(len(dataset)) if class_label == dataset.classes[dataset.targets[i]]]\n",
    "    \n",
    "    if not class_indices:\n",
    "        print(f\"No images found for class {class_label}\")\n",
    "        return\n",
    "\n",
    "    random_index = random.choice(class_indices)\n",
    "    image, _ = dataset[random_index]\n",
    "\n",
    "    plt.imshow(image.permute(1, 2, 0))  # Rearrange the dimensions for proper display\n",
    "    plt.title(class_label)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a random image from the first 5 classes\n",
    "for _ in range(5):\n",
    "    visualize_random_image(object_categories, class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean (R, G, B): 0.5868813143266484 0.5901318658082698 0.5895006401120755\n",
      "Std (R, G, B): 0.15651534738684142 0.16069732546255797 0.16360452319890667\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables to accumulate the sum and sum of squares for each channel\n",
    "mean_r, mean_g, mean_b = 0, 0, 0\n",
    "std_r, std_g, std_b = 0, 0, 0\n",
    "\n",
    "# Loop through the dataset and accumulate the values\n",
    "for image, _ in object_categories:\n",
    "    image = np.array(image)  # Convert the image to a NumPy array\n",
    "    mean_r += np.mean(image[:, :, 0])\n",
    "    mean_g += np.mean(image[:, :, 1])\n",
    "    mean_b += np.mean(image[:, :, 2])\n",
    "    std_r += np.std(image[:, :, 0]) ** 2  # Square of the standard deviation\n",
    "    std_g += np.std(image[:, :, 1]) ** 2\n",
    "    std_b += np.std(image[:, :, 2]) ** 2\n",
    "\n",
    "# Calculate the overall mean and standard deviation for each channel\n",
    "total_samples = len(object_categories)\n",
    "mean_r /= total_samples\n",
    "mean_g /= total_samples\n",
    "mean_b /= total_samples\n",
    "std_r = np.sqrt(std_r / total_samples)  # Take the square root\n",
    "std_g = np.sqrt(std_g / total_samples)\n",
    "std_b = np.sqrt(std_b / total_samples)\n",
    "\n",
    "# Print the computed values\n",
    "print(\"Mean (R, G, B):\", mean_r, mean_g, mean_b)\n",
    "print(\"Std (R, G, B):\", std_r, std_g, std_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
